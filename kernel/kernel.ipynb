{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model, which train embedding for each ingredient and than perform simple softmax classification.\n",
    "import json, re\n",
    "from collections import UserDict, Counter\n",
    "from tqdm import tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, MaxPooling1D, Reshape, AveragePooling2D, Flatten, Dropout\n",
    "import random, keras\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "MAX_INGREDIENT_DIM = 8\n",
    "MAX_INGREDIENT_COUNT = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellmannâ€ or best food canola cholesterol free mayonnais\n",
      "2 1/2 to 3 lb. chicken\n",
      "2 1/2 to 3 lb. chicken\n",
      "39774\n",
      "3083\n",
      "[(9, 3753), (10, 3677), (8, 3555), (11, 3512), (7, 3330), (12, 3146), (13, 2698), (6, 2661), (14, 2254), (5, 1892), (15, 1808), (16, 1439), (17, 1160), (4, 1128), (18, 879), (19, 610), (3, 549), (20, 504), (21, 313), (22, 218), (2, 193), (23, 141), (24, 91), (25, 72), (26, 46), (28, 27), (1, 22), (29, 21), (27, 20), (30, 15), (31, 11), (32, 4), (36, 4), (33, 4), (40, 3), (34, 3), (35, 3), (38, 2), (49, 2), (65, 1), (52, 1), (59, 1), (43, 1)]\n"
     ]
    }
   ],
   "source": [
    "class BiDict(UserDict):\n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "        self.data[value] = key\n",
    "    \n",
    "INGREDIENTS, CUISINES = BiDict(), BiDict()\n",
    "WORDS = BiDict()\n",
    "INGREDIENTS_IDS = []\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = name.replace('’', \"'\")\n",
    "    name = re.sub(\"[®™!]\", ' ', name)\n",
    "    name = re.sub('\\(.+\\)', ' ', name)\n",
    "    if ',' in name:\n",
    "        name, *rest = name.split(',')\n",
    "    name = re.sub('\\s+', ' ', name)\n",
    "    \n",
    "    if not re.fullmatch('[- \\'a-zèçîíúéâ&0-9%.]+', name):\n",
    "        print(name)\n",
    "        return None\n",
    "    return name.strip()\n",
    "\n",
    "records = []\n",
    "lengths = Counter()\n",
    "words = Counter()\n",
    "\n",
    "with open('../input/train.json') as file:\n",
    "    for record in json.load(file):\n",
    "        cuisine_id = CUISINES.setdefault(record['cuisine'], len(CUISINES)//2)\n",
    "        ingredients = []\n",
    "        for ingredient in record['ingredients']:\n",
    "            ingredient = normalize_name(ingredient)\n",
    "            if ingredient is None:\n",
    "                continue\n",
    "            \n",
    "            if ingredient not in INGREDIENTS:\n",
    "                ingredient_words = ingredient.split(' ')#[:MAX_INGREDIENT_DIM]\n",
    "                ingredient_ids = [WORDS.setdefault(i, len(WORDS)//2) for i in ingredient_words]\n",
    "                INGREDIENTS[ingredient] = len(INGREDIENTS_IDS)\n",
    "                INGREDIENTS_IDS.append(ingredient_ids)\n",
    "            \n",
    "            ingredients.append(INGREDIENTS[ingredient])\n",
    "        lengths[len(ingredients)] += 1\n",
    "        records.append((cuisine_id, ingredients))\n",
    "        \n",
    "print(len(records))\n",
    "print(len(WORDS)//2)\n",
    "print(lengths.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 16, 8)             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 16, 8, 32)         98656     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 16, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 105,460\n",
      "Trainable params: 105,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ingredients_count = 5\n",
    "emb_dim = 32\n",
    "output_classes = 20\n",
    "\n",
    "a = Input(shape=(MAX_INGREDIENT_COUNT, MAX_INGREDIENT_DIM))\n",
    "\n",
    "b = Embedding(len(WORDS)//2, emb_dim)(a)\n",
    "b = Dropout(rate=0.1)(b)\n",
    "b = AveragePooling2D(pool_size=(1,MAX_INGREDIENT_DIM))(b)\n",
    "# b = MaxPooling2D(pool_size=(1, MAX_INGREDIENT_DIM))(emb)\n",
    "b = Reshape((-1,emb_dim))(b)\n",
    "b = MaxPooling1D(pool_size=(MAX_INGREDIENT_COUNT,))(b)\n",
    "b = Flatten()(b)\n",
    "# b = Dense(512, activation='tanh')(b)\n",
    "# b = Dense(128, activation='tanh')(b)\n",
    "# b = Dropout(rate=0.1)(b)\n",
    "b = Dense(128, activation='relu')(b)\n",
    "b = Dropout(rate=0.1)(b)\n",
    "\n",
    "d = Dense(output_classes, activation='softmax')(b)\n",
    "\n",
    "model = Model(inputs=a, outputs=d)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65536 samples, validate on 65536 samples\n",
      "Epoch 1/50\n",
      "65536/65536 [==============================] - 6s 88us/step - loss: 2.7658 - acc: 0.1806 - val_loss: 2.5447 - val_acc: 0.3231\n",
      "Epoch 2/50\n",
      "65536/65536 [==============================] - 6s 85us/step - loss: 2.3509 - acc: 0.3211 - val_loss: 2.0688 - val_acc: 0.4153\n",
      "Epoch 3/50\n",
      "65536/65536 [==============================] - 5s 83us/step - loss: 1.7659 - acc: 0.5076 - val_loss: 1.5367 - val_acc: 0.5571\n",
      "Epoch 4/50\n",
      "65536/65536 [==============================] - 5s 78us/step - loss: 1.4022 - acc: 0.5914 - val_loss: 1.3027 - val_acc: 0.6175\n",
      "Epoch 5/50\n",
      "65536/65536 [==============================] - 5s 75us/step - loss: 1.2207 - acc: 0.6380 - val_loss: 1.1770 - val_acc: 0.6522\n",
      "Epoch 6/50\n",
      "65536/65536 [==============================] - 5s 81us/step - loss: 1.1127 - acc: 0.6666 - val_loss: 1.0998 - val_acc: 0.6720\n",
      "Epoch 7/50\n",
      "65536/65536 [==============================] - 5s 78us/step - loss: 1.0381 - acc: 0.6865 - val_loss: 1.0449 - val_acc: 0.6877\n",
      "Epoch 8/50\n",
      "65536/65536 [==============================] - 5s 75us/step - loss: 0.9790 - acc: 0.7043 - val_loss: 1.0027 - val_acc: 0.6988\n",
      "Epoch 9/50\n",
      "65536/65536 [==============================] - 5s 78us/step - loss: 0.9293 - acc: 0.7197 - val_loss: 0.9665 - val_acc: 0.7094\n",
      "Epoch 10/50\n",
      "65536/65536 [==============================] - 5s 77us/step - loss: 0.8892 - acc: 0.7303 - val_loss: 0.9378 - val_acc: 0.7185\n",
      "Epoch 11/50\n",
      "65536/65536 [==============================] - 5s 75us/step - loss: 0.8520 - acc: 0.7422 - val_loss: 0.9129 - val_acc: 0.7264\n",
      "Epoch 12/50\n",
      "65536/65536 [==============================] - 5s 77us/step - loss: 0.8224 - acc: 0.7509 - val_loss: 0.8923 - val_acc: 0.7314\n",
      "Epoch 13/50\n",
      "65536/65536 [==============================] - 5s 73us/step - loss: 0.7947 - acc: 0.7584 - val_loss: 0.8763 - val_acc: 0.7367\n",
      "Epoch 14/50\n",
      "65536/65536 [==============================] - 5s 71us/step - loss: 0.7693 - acc: 0.7672 - val_loss: 0.8622 - val_acc: 0.7409\n",
      "Epoch 15/50\n",
      "65536/65536 [==============================] - 5s 73us/step - loss: 0.7481 - acc: 0.7734 - val_loss: 0.8510 - val_acc: 0.7439\n",
      "Epoch 16/50\n",
      "65536/65536 [==============================] - 5s 77us/step - loss: 0.7288 - acc: 0.7789 - val_loss: 0.8405 - val_acc: 0.7479\n",
      "Epoch 17/50\n",
      "65536/65536 [==============================] - 5s 75us/step - loss: 0.7125 - acc: 0.7845 - val_loss: 0.8328 - val_acc: 0.7499\n",
      "Epoch 18/50\n",
      "65536/65536 [==============================] - 5s 77us/step - loss: 0.6940 - acc: 0.7894 - val_loss: 0.8261 - val_acc: 0.7519\n",
      "Epoch 19/50\n",
      "65536/65536 [==============================] - 5s 74us/step - loss: 0.6818 - acc: 0.7929 - val_loss: 0.8196 - val_acc: 0.7543\n",
      "Epoch 20/50\n",
      "65536/65536 [==============================] - 5s 73us/step - loss: 0.6685 - acc: 0.7974 - val_loss: 0.8140 - val_acc: 0.7564\n",
      "Epoch 21/50\n",
      "65536/65536 [==============================] - 5s 73us/step - loss: 0.6552 - acc: 0.7996 - val_loss: 0.8094 - val_acc: 0.7571\n",
      "Epoch 22/50\n",
      "65536/65536 [==============================] - 5s 73us/step - loss: 0.6447 - acc: 0.8027 - val_loss: 0.8055 - val_acc: 0.7595\n",
      "Epoch 23/50\n",
      "65536/65536 [==============================] - 5s 76us/step - loss: 0.6361 - acc: 0.8068 - val_loss: 0.8024 - val_acc: 0.7597\n",
      "Epoch 24/50\n",
      "65536/65536 [==============================] - 5s 75us/step - loss: 0.6256 - acc: 0.8097 - val_loss: 0.8000 - val_acc: 0.7611\n",
      "Epoch 25/50\n",
      "65536/65536 [==============================] - 5s 73us/step - loss: 0.6157 - acc: 0.8123 - val_loss: 0.7972 - val_acc: 0.7625\n",
      "Epoch 26/50\n",
      "65536/65536 [==============================] - 5s 74us/step - loss: 0.6058 - acc: 0.8154 - val_loss: 0.7959 - val_acc: 0.7627\n",
      "Epoch 27/50\n",
      "65536/65536 [==============================] - 5s 76us/step - loss: 0.5994 - acc: 0.8171 - val_loss: 0.7950 - val_acc: 0.7640\n",
      "Epoch 28/50\n",
      "65536/65536 [==============================] - 5s 78us/step - loss: 0.5908 - acc: 0.8187 - val_loss: 0.7926 - val_acc: 0.7654\n",
      "Epoch 29/50\n",
      "65536/65536 [==============================] - 5s 76us/step - loss: 0.5848 - acc: 0.8221 - val_loss: 0.7922 - val_acc: 0.7657\n",
      "Epoch 30/50\n",
      "65536/65536 [==============================] - 5s 74us/step - loss: 0.5779 - acc: 0.8244 - val_loss: 0.7909 - val_acc: 0.7663\n",
      "Epoch 31/50\n",
      "65536/65536 [==============================] - 5s 72us/step - loss: 0.5698 - acc: 0.8266 - val_loss: 0.7907 - val_acc: 0.7671\n",
      "Epoch 32/50\n",
      "65536/65536 [==============================] - 5s 70us/step - loss: 0.5654 - acc: 0.8263 - val_loss: 0.7895 - val_acc: 0.7673\n",
      "Epoch 33/50\n",
      "65536/65536 [==============================] - 4s 62us/step - loss: 0.5600 - acc: 0.8294 - val_loss: 0.7900 - val_acc: 0.7669\n",
      "Epoch 34/50\n",
      "65536/65536 [==============================] - 4s 66us/step - loss: 0.5534 - acc: 0.8315 - val_loss: 0.7900 - val_acc: 0.7678\n",
      "Train on 65536 samples, validate on 65536 samples\n",
      "Epoch 1/50\n",
      "65536/65536 [==============================] - 4s 55us/step - loss: 0.8042 - acc: 0.7624 - val_loss: 0.7538 - val_acc: 0.7738\n",
      "Epoch 2/50\n",
      "65536/65536 [==============================] - 4s 55us/step - loss: 0.7372 - acc: 0.7781 - val_loss: 0.7387 - val_acc: 0.7772\n",
      "Epoch 3/50\n",
      "65536/65536 [==============================] - 4s 57us/step - loss: 0.7058 - acc: 0.7873 - val_loss: 0.7306 - val_acc: 0.7790\n",
      "Epoch 4/50\n",
      "65536/65536 [==============================] - 5s 82us/step - loss: 0.6828 - acc: 0.7923 - val_loss: 0.7259 - val_acc: 0.7794\n",
      "Epoch 5/50\n",
      "65536/65536 [==============================] - 4s 62us/step - loss: 0.6643 - acc: 0.7984 - val_loss: 0.7229 - val_acc: 0.7804\n",
      "Epoch 6/50\n",
      "65536/65536 [==============================] - 4s 54us/step - loss: 0.6511 - acc: 0.8022 - val_loss: 0.7211 - val_acc: 0.7806\n",
      "Epoch 7/50\n",
      "65536/65536 [==============================] - 3s 52us/step - loss: 0.6385 - acc: 0.8050 - val_loss: 0.7210 - val_acc: 0.7809\n",
      "Epoch 8/50\n",
      "65536/65536 [==============================] - 4s 55us/step - loss: 0.6255 - acc: 0.8097 - val_loss: 0.7186 - val_acc: 0.7825\n",
      "Epoch 9/50\n",
      "65536/65536 [==============================] - 4s 54us/step - loss: 0.6186 - acc: 0.8119 - val_loss: 0.7171 - val_acc: 0.7825\n",
      "Epoch 10/50\n",
      "65536/65536 [==============================] - 4s 61us/step - loss: 0.6056 - acc: 0.8146 - val_loss: 0.7170 - val_acc: 0.7836\n",
      "Epoch 11/50\n",
      "65536/65536 [==============================] - 4s 64us/step - loss: 0.5983 - acc: 0.8163 - val_loss: 0.7158 - val_acc: 0.7827\n",
      "Epoch 12/50\n",
      "65536/65536 [==============================] - 4s 57us/step - loss: 0.5909 - acc: 0.8200 - val_loss: 0.7151 - val_acc: 0.7841\n",
      "Epoch 13/50\n",
      "65536/65536 [==============================] - 4s 58us/step - loss: 0.5823 - acc: 0.8226 - val_loss: 0.7151 - val_acc: 0.7837\n",
      "Epoch 14/50\n",
      "65536/65536 [==============================] - 4s 58us/step - loss: 0.5771 - acc: 0.8231 - val_loss: 0.7156 - val_acc: 0.7841\n",
      "Epoch 15/50\n",
      "65536/65536 [==============================] - 4s 56us/step - loss: 0.5701 - acc: 0.8251 - val_loss: 0.7161 - val_acc: 0.7840\n"
     ]
    }
   ],
   "source": [
    "def get_data(n):\n",
    "    inputs, outputs = [], []\n",
    "    for i in range(n):\n",
    "        cuisine, items = random.choice(records)\n",
    "        items = random.choices(items, k=MAX_INGREDIENT_COUNT)\n",
    "        items = [random.choices(INGREDIENTS_IDS[i], k=MAX_INGREDIENT_DIM) for i in items]\n",
    "        outputs.append(cuisine)\n",
    "        assert all(len(x) == MAX_INGREDIENT_DIM for x in items)\n",
    "        inputs.append(items)\n",
    "        \n",
    "    return np.array(inputs), keras.utils.to_categorical(np.array(outputs), num_classes=output_classes)\n",
    "\n",
    "# print(get_data(5))\n",
    "bsize = 2**16\n",
    "\n",
    "batch0, batch1 = None, get_data(bsize)\n",
    "for i in range(2):\n",
    "    batch0 = batch1\n",
    "    batch1 = get_data(bsize)\n",
    "    \n",
    "    model.fit(*batch0, verbose=1, epochs=50, batch_size=2**10, validation_data=batch1, callbacks=[EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3083, 32)\n",
      "(3083,)\n",
      "romaine e-fu 0.58718914\n",
      "lettuce garlic 0.7340528\n",
      "black zucchini 0.73226404\n",
      "olives vine 0.64733803\n",
      "grape anise 0.59557295\n",
      "tomatoes bell 0.7219744\n",
      "garlic salt 0.7721785\n",
      "pepper bay 0.7187047\n",
      "purple salt 0.76434726\n",
      "onion minced 0.68547773\n",
      "seasoning ben's 0.4888513\n",
      "garbanzo buckwheat 0.59822273\n",
      "beans black 0.6009315\n",
      "feta crumbles 0.8137418\n",
      "cheese pizza 0.65302044\n",
      "crumbles feta 0.81374186\n",
      "plain crumbles 0.5743107\n",
      "flour lard 0.6877942\n",
      "ground lentils 0.7262362\n",
      "salt juice 0.78417885\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "print(weights.shape)\n",
    "w2=np.sqrt(np.sum(weights*weights, axis=1))\n",
    "print(w2.shape)\n",
    "\n",
    "for i in range(0,20):\n",
    "    w = (np.matmul(weights, weights[i]) / w2)/w2[i]\n",
    "    w[i] = 0\n",
    "    b = np.argmax(w)\n",
    "    \n",
    "    print(WORDS[i], WORDS[b], w[b])\n",
    "\n",
    "# print(WORDS[''], np.sum(weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9944 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 57/9944 [00:00<00:17, 563.18it/s]\u001b[A\n",
      "  1%|          | 118/9944 [00:00<00:17, 574.86it/s]\u001b[A\n",
      "  2%|▏         | 178/9944 [00:00<00:16, 581.35it/s]\u001b[A\n",
      "  2%|▏         | 235/9944 [00:00<00:16, 576.96it/s]\u001b[A\n",
      "  3%|▎         | 294/9944 [00:00<00:16, 576.78it/s]\u001b[A\n",
      "  3%|▎         | 348/9944 [00:00<00:16, 564.50it/s]\u001b[A\n",
      "  4%|▍         | 400/9944 [00:00<00:17, 543.61it/s]\u001b[A\n",
      "  5%|▍         | 450/9944 [00:00<00:18, 519.11it/s]\u001b[A\n",
      "  5%|▌         | 503/9944 [00:00<00:18, 520.27it/s]\u001b[A\n",
      "  6%|▌         | 554/9944 [00:01<00:19, 490.35it/s]\u001b[A\n",
      "  6%|▌         | 608/9944 [00:01<00:18, 503.06it/s]\u001b[A\n",
      "  7%|▋         | 660/9944 [00:01<00:18, 506.51it/s]\u001b[A\n",
      "  7%|▋         | 714/9944 [00:01<00:17, 514.54it/s]\u001b[A\n",
      "  8%|▊         | 770/9944 [00:01<00:17, 526.16it/s]\u001b[A\n",
      "  8%|▊         | 828/9944 [00:01<00:16, 538.77it/s]\u001b[A\n",
      "  9%|▉         | 883/9944 [00:01<00:16, 541.66it/s]\u001b[A\n",
      "  9%|▉         | 938/9944 [00:01<00:16, 534.38it/s]\u001b[A\n",
      " 10%|▉         | 994/9944 [00:01<00:16, 541.16it/s]\u001b[A\n",
      " 11%|█         | 1054/9944 [00:01<00:15, 556.77it/s]\u001b[A\n",
      " 11%|█         | 1110/9944 [00:02<00:16, 546.77it/s]\u001b[A\n",
      " 12%|█▏        | 1168/9944 [00:02<00:15, 555.27it/s]\u001b[A\n",
      " 12%|█▏        | 1226/9944 [00:02<00:15, 562.33it/s]\u001b[A\n",
      " 13%|█▎        | 1283/9944 [00:02<00:16, 537.01it/s]\u001b[A\n",
      " 13%|█▎        | 1338/9944 [00:02<00:16, 516.11it/s]\u001b[A\n",
      " 14%|█▍        | 1394/9944 [00:02<00:16, 528.30it/s]\u001b[A\n",
      " 15%|█▍        | 1449/9944 [00:02<00:15, 532.89it/s]\u001b[A\n",
      " 15%|█▌        | 1503/9944 [00:02<00:17, 494.43it/s]\u001b[A\n",
      " 16%|█▌        | 1554/9944 [00:02<00:17, 473.73it/s]\u001b[A\n",
      " 16%|█▌        | 1603/9944 [00:03<00:20, 398.02it/s]\u001b[A\n",
      " 17%|█▋        | 1646/9944 [00:03<00:22, 365.51it/s]\u001b[A\n",
      " 17%|█▋        | 1685/9944 [00:03<00:24, 334.10it/s]\u001b[A\n",
      " 17%|█▋        | 1721/9944 [00:03<00:24, 330.46it/s]\u001b[A\n",
      " 18%|█▊        | 1756/9944 [00:03<00:25, 322.51it/s]\u001b[A\n",
      " 18%|█▊        | 1790/9944 [00:03<00:26, 311.76it/s]\u001b[A\n",
      " 18%|█▊        | 1831/9944 [00:03<00:24, 334.57it/s]\u001b[A\n",
      " 19%|█▉        | 1870/9944 [00:03<00:23, 348.80it/s]\u001b[A\n",
      " 19%|█▉        | 1908/9944 [00:04<00:22, 355.48it/s]\u001b[A\n",
      " 20%|█▉        | 1947/9944 [00:04<00:21, 363.61it/s]\u001b[A\n",
      " 20%|█▉        | 1984/9944 [00:04<00:22, 356.49it/s]\u001b[A\n",
      " 20%|██        | 2021/9944 [00:04<00:22, 350.14it/s]\u001b[A\n",
      " 21%|██        | 2057/9944 [00:04<00:23, 339.50it/s]\u001b[A\n",
      " 21%|██        | 2097/9944 [00:04<00:22, 354.49it/s]\u001b[A\n",
      " 21%|██▏       | 2133/9944 [00:04<00:22, 354.46it/s]\u001b[A\n",
      " 22%|██▏       | 2169/9944 [00:04<00:22, 344.35it/s]\u001b[A\n",
      " 22%|██▏       | 2206/9944 [00:04<00:22, 349.69it/s]\u001b[A\n",
      " 23%|██▎       | 2242/9944 [00:04<00:22, 349.07it/s]\u001b[A\n",
      " 23%|██▎       | 2278/9944 [00:05<00:22, 344.61it/s]\u001b[A\n",
      " 23%|██▎       | 2314/9944 [00:05<00:21, 347.97it/s]\u001b[A\n",
      " 24%|██▎       | 2349/9944 [00:05<00:21, 347.41it/s]\u001b[A\n",
      " 24%|██▍       | 2384/9944 [00:05<00:22, 335.76it/s]\u001b[A\n",
      " 24%|██▍       | 2423/9944 [00:05<00:21, 346.42it/s]\u001b[A\n",
      " 25%|██▍       | 2458/9944 [00:05<00:21, 341.29it/s]\u001b[A\n",
      " 25%|██▌       | 2502/9944 [00:05<00:20, 365.60it/s]\u001b[A\n",
      " 26%|██▌       | 2545/9944 [00:05<00:19, 382.47it/s]\u001b[A\n",
      " 26%|██▌       | 2598/9944 [00:05<00:17, 415.20it/s]\u001b[A\n",
      " 27%|██▋       | 2646/9944 [00:06<00:16, 432.21it/s]\u001b[A\n",
      " 27%|██▋       | 2697/9944 [00:06<00:16, 452.39it/s]\u001b[A\n",
      " 28%|██▊       | 2744/9944 [00:06<00:16, 443.80it/s]\u001b[A\n",
      " 28%|██▊       | 2790/9944 [00:06<00:16, 421.38it/s]\u001b[A\n",
      " 28%|██▊       | 2833/9944 [00:06<00:17, 408.18it/s]\u001b[A\n",
      " 29%|██▉       | 2875/9944 [00:06<00:19, 371.33it/s]\u001b[A\n",
      " 29%|██▉       | 2914/9944 [00:06<00:19, 351.75it/s]\u001b[A\n",
      " 30%|██▉       | 2955/9944 [00:06<00:19, 366.27it/s]\u001b[A\n",
      " 30%|███       | 2996/9944 [00:06<00:18, 377.28it/s]\u001b[A\n",
      " 31%|███       | 3035/9944 [00:07<00:18, 365.93it/s]\u001b[A\n",
      " 31%|███       | 3073/9944 [00:07<00:19, 349.01it/s]\u001b[A\n",
      " 31%|███▏      | 3123/9944 [00:07<00:17, 383.50it/s]\u001b[A\n",
      " 32%|███▏      | 3163/9944 [00:07<00:18, 369.18it/s]\u001b[A\n",
      " 32%|███▏      | 3202/9944 [00:07<00:18, 373.24it/s]\u001b[A\n",
      " 33%|███▎      | 3244/9944 [00:07<00:17, 385.33it/s]\u001b[A\n",
      " 33%|███▎      | 3296/9944 [00:07<00:15, 417.31it/s]\u001b[A\n",
      " 34%|███▎      | 3348/9944 [00:07<00:14, 442.28it/s]\u001b[A\n",
      " 34%|███▍      | 3401/9944 [00:07<00:14, 465.30it/s]\u001b[A\n",
      " 35%|███▍      | 3457/9944 [00:07<00:13, 489.83it/s]\u001b[A\n",
      " 35%|███▌      | 3508/9944 [00:08<00:13, 483.50it/s]\u001b[A\n",
      " 36%|███▌      | 3563/9944 [00:08<00:12, 501.45it/s]\u001b[A\n",
      " 36%|███▋      | 3623/9944 [00:08<00:12, 525.76it/s]\u001b[A\n",
      " 37%|███▋      | 3677/9944 [00:08<00:12, 516.95it/s]\u001b[A\n",
      " 38%|███▊      | 3730/9944 [00:08<00:12, 483.11it/s]\u001b[A\n",
      " 38%|███▊      | 3780/9944 [00:08<00:12, 478.26it/s]\u001b[A\n",
      " 39%|███▊      | 3836/9944 [00:08<00:12, 498.89it/s]\u001b[A\n",
      " 39%|███▉      | 3887/9944 [00:08<00:12, 499.87it/s]\u001b[A\n",
      " 40%|███▉      | 3941/9944 [00:08<00:11, 511.20it/s]\u001b[A\n",
      " 40%|████      | 3996/9944 [00:09<00:11, 521.38it/s]\u001b[A\n",
      " 41%|████      | 4049/9944 [00:09<00:12, 483.31it/s]\u001b[A\n",
      " 41%|████      | 4101/9944 [00:09<00:11, 492.72it/s]\u001b[A\n",
      " 42%|████▏     | 4151/9944 [00:09<00:11, 483.77it/s]\u001b[A\n",
      " 42%|████▏     | 4207/9944 [00:09<00:11, 503.92it/s]\u001b[A\n",
      " 43%|████▎     | 4258/9944 [00:09<00:11, 496.05it/s]\u001b[A\n",
      " 43%|████▎     | 4311/9944 [00:09<00:11, 504.46it/s]\u001b[A\n",
      " 44%|████▍     | 4362/9944 [00:09<00:11, 489.70it/s]\u001b[A\n",
      " 44%|████▍     | 4414/9944 [00:09<00:11, 496.98it/s]\u001b[A\n",
      " 45%|████▍     | 4472/9944 [00:10<00:10, 517.44it/s]\u001b[A\n",
      " 46%|████▌     | 4525/9944 [00:10<00:10, 508.31it/s]\u001b[A\n",
      " 46%|████▌     | 4577/9944 [00:10<00:11, 467.00it/s]\u001b[A\n",
      " 47%|████▋     | 4625/9944 [00:10<00:11, 450.80it/s]\u001b[A\n",
      " 47%|████▋     | 4683/9944 [00:10<00:10, 481.59it/s]\u001b[A\n",
      " 48%|████▊     | 4738/9944 [00:10<00:10, 489.14it/s]\u001b[A\n",
      " 48%|████▊     | 4791/9944 [00:10<00:10, 499.18it/s]\u001b[A\n",
      " 49%|████▉     | 4852/9944 [00:10<00:09, 527.44it/s]\u001b[A\n",
      " 49%|████▉     | 4906/9944 [00:10<00:09, 515.95it/s]\u001b[A\n",
      " 50%|████▉     | 4959/9944 [00:11<00:10, 484.41it/s]\u001b[A\n",
      " 50%|█████     | 5015/9944 [00:11<00:09, 504.35it/s]\u001b[A\n",
      " 51%|█████     | 5075/9944 [00:11<00:09, 527.84it/s]\u001b[A\n",
      " 52%|█████▏    | 5129/9944 [00:11<00:09, 504.78it/s]\u001b[A\n",
      " 52%|█████▏    | 5185/9944 [00:11<00:09, 519.83it/s]\u001b[A\n",
      " 53%|█████▎    | 5243/9944 [00:11<00:08, 534.70it/s]\u001b[A\n",
      " 53%|█████▎    | 5298/9944 [00:11<00:08, 529.81it/s]\u001b[A\n",
      " 54%|█████▍    | 5357/9944 [00:11<00:08, 546.15it/s]\u001b[A\n",
      " 54%|█████▍    | 5413/9944 [00:11<00:09, 500.29it/s]\u001b[A\n",
      " 55%|█████▍    | 5465/9944 [00:11<00:09, 472.76it/s]\u001b[A\n",
      " 55%|█████▌    | 5514/9944 [00:12<00:10, 439.56it/s]\u001b[A\n",
      " 56%|█████▌    | 5560/9944 [00:12<00:11, 382.73it/s]\u001b[A\n",
      " 56%|█████▋    | 5601/9944 [00:12<00:11, 388.68it/s]\u001b[A\n",
      " 57%|█████▋    | 5649/9944 [00:12<00:10, 410.69it/s]\u001b[A\n",
      " 57%|█████▋    | 5697/9944 [00:12<00:09, 427.62it/s]\u001b[A\n",
      " 58%|█████▊    | 5749/9944 [00:12<00:09, 451.26it/s]\u001b[A\n",
      " 58%|█████▊    | 5803/9944 [00:12<00:08, 473.16it/s]\u001b[A\n",
      " 59%|█████▉    | 5857/9944 [00:12<00:08, 489.44it/s]\u001b[A\n",
      " 59%|█████▉    | 5911/9944 [00:12<00:08, 503.20it/s]\u001b[A\n",
      " 60%|█████▉    | 5965/9944 [00:13<00:07, 510.29it/s]\u001b[A\n",
      " 61%|██████    | 6021/9944 [00:13<00:07, 521.79it/s]\u001b[A\n",
      " 61%|██████    | 6075/9944 [00:13<00:07, 526.44it/s]\u001b[A\n",
      " 62%|██████▏   | 6128/9944 [00:13<00:07, 506.49it/s]\u001b[A\n",
      " 62%|██████▏   | 6183/9944 [00:13<00:07, 517.03it/s]\u001b[A\n",
      " 63%|██████▎   | 6238/9944 [00:13<00:07, 525.58it/s]\u001b[A\n",
      " 63%|██████▎   | 6292/9944 [00:13<00:06, 527.18it/s]\u001b[A\n",
      " 64%|██████▍   | 6347/9944 [00:13<00:06, 533.10it/s]\u001b[A\n",
      " 64%|██████▍   | 6401/9944 [00:13<00:06, 510.87it/s]\u001b[A\n",
      " 65%|██████▍   | 6453/9944 [00:14<00:06, 508.61it/s]\u001b[A\n",
      " 65%|██████▌   | 6508/9944 [00:14<00:06, 520.07it/s]\u001b[A\n",
      " 66%|██████▌   | 6563/9944 [00:14<00:06, 528.20it/s]\u001b[A\n",
      " 67%|██████▋   | 6617/9944 [00:14<00:06, 530.33it/s]\u001b[A\n",
      " 67%|██████▋   | 6671/9944 [00:14<00:06, 517.41it/s]\u001b[A\n",
      " 68%|██████▊   | 6725/9944 [00:14<00:06, 522.82it/s]\u001b[A\n",
      " 68%|██████▊   | 6779/9944 [00:14<00:06, 526.80it/s]\u001b[A\n",
      " 69%|██████▊   | 6833/9944 [00:14<00:05, 529.64it/s]\u001b[A\n",
      " 69%|██████▉   | 6887/9944 [00:14<00:05, 530.00it/s]\u001b[A\n",
      " 70%|██████▉   | 6941/9944 [00:14<00:05, 530.88it/s]\u001b[A\n",
      " 70%|███████   | 6995/9944 [00:15<00:05, 533.31it/s]\u001b[A\n",
      " 71%|███████   | 7051/9944 [00:15<00:05, 539.79it/s]\u001b[A\n",
      " 71%|███████▏  | 7107/9944 [00:15<00:05, 544.40it/s]\u001b[A\n",
      " 72%|███████▏  | 7162/9944 [00:15<00:05, 540.06it/s]\u001b[A\n",
      " 73%|███████▎  | 7217/9944 [00:15<00:05, 542.33it/s]\u001b[A\n",
      " 73%|███████▎  | 7272/9944 [00:15<00:05, 526.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 7326/9944 [00:15<00:04, 528.99it/s]\u001b[A\n",
      " 74%|███████▍  | 7379/9944 [00:15<00:04, 523.28it/s]\u001b[A\n",
      " 75%|███████▍  | 7432/9944 [00:15<00:04, 517.89it/s]\u001b[A\n",
      " 75%|███████▌  | 7484/9944 [00:15<00:04, 510.18it/s]\u001b[A\n",
      " 76%|███████▌  | 7538/9944 [00:16<00:04, 518.68it/s]\u001b[A\n",
      " 76%|███████▋  | 7590/9944 [00:16<00:04, 518.76it/s]\u001b[A\n",
      " 77%|███████▋  | 7643/9944 [00:16<00:04, 522.00it/s]\u001b[A\n",
      " 77%|███████▋  | 7697/9944 [00:16<00:04, 527.02it/s]\u001b[A\n",
      " 78%|███████▊  | 7753/9944 [00:16<00:04, 534.28it/s]\u001b[A\n",
      " 79%|███████▊  | 7809/9944 [00:16<00:03, 538.20it/s]\u001b[A\n",
      " 79%|███████▉  | 7863/9944 [00:16<00:03, 528.98it/s]\u001b[A\n",
      " 80%|███████▉  | 7916/9944 [00:16<00:03, 525.85it/s]\u001b[A\n",
      " 80%|████████  | 7969/9944 [00:16<00:03, 524.67it/s]\u001b[A\n",
      " 81%|████████  | 8024/9944 [00:16<00:03, 530.29it/s]\u001b[A\n",
      " 81%|████████  | 8078/9944 [00:17<00:03, 530.40it/s]\u001b[A\n",
      " 82%|████████▏ | 8132/9944 [00:17<00:03, 528.42it/s]\u001b[A\n",
      " 82%|████████▏ | 8185/9944 [00:17<00:03, 520.86it/s]\u001b[A\n",
      " 83%|████████▎ | 8238/9944 [00:17<00:03, 462.41it/s]\u001b[A\n",
      " 83%|████████▎ | 8286/9944 [00:17<00:04, 405.88it/s]\u001b[A\n",
      " 84%|████████▍ | 8329/9944 [00:17<00:04, 383.61it/s]\u001b[A\n",
      " 84%|████████▍ | 8370/9944 [00:17<00:04, 363.87it/s]\u001b[A\n",
      " 85%|████████▍ | 8408/9944 [00:17<00:04, 347.45it/s]\u001b[A\n",
      " 85%|████████▍ | 8448/9944 [00:18<00:04, 359.57it/s]\u001b[A\n",
      " 85%|████████▌ | 8489/9944 [00:18<00:03, 371.99it/s]\u001b[A\n",
      " 86%|████████▌ | 8527/9944 [00:18<00:04, 342.77it/s]\u001b[A\n",
      " 86%|████████▌ | 8565/9944 [00:18<00:03, 352.86it/s]\u001b[A\n",
      " 87%|████████▋ | 8604/9944 [00:18<00:03, 361.79it/s]\u001b[A\n",
      " 87%|████████▋ | 8641/9944 [00:18<00:03, 351.17it/s]\u001b[A\n",
      " 87%|████████▋ | 8679/9944 [00:18<00:03, 357.53it/s]\u001b[A\n",
      " 88%|████████▊ | 8719/9944 [00:18<00:03, 369.00it/s]\u001b[A\n",
      " 88%|████████▊ | 8757/9944 [00:18<00:03, 368.26it/s]\u001b[A\n",
      " 88%|████████▊ | 8795/9944 [00:19<00:03, 367.72it/s]\u001b[A\n",
      " 89%|████████▉ | 8834/9944 [00:19<00:02, 374.11it/s]\u001b[A\n",
      " 89%|████████▉ | 8872/9944 [00:19<00:02, 375.80it/s]\u001b[A\n",
      " 90%|████████▉ | 8911/9944 [00:19<00:02, 379.94it/s]\u001b[A\n",
      " 90%|█████████ | 8950/9944 [00:19<00:02, 375.74it/s]\u001b[A\n",
      " 90%|█████████ | 8988/9944 [00:19<00:02, 363.22it/s]\u001b[A\n",
      " 91%|█████████ | 9025/9944 [00:19<00:02, 351.76it/s]\u001b[A\n",
      " 91%|█████████ | 9062/9944 [00:19<00:02, 355.38it/s]\u001b[A\n",
      " 91%|█████████▏| 9098/9944 [00:19<00:02, 325.61it/s]\u001b[A\n",
      " 92%|█████████▏| 9134/9944 [00:19<00:02, 333.44it/s]\u001b[A\n",
      " 92%|█████████▏| 9173/9944 [00:20<00:02, 348.15it/s]\u001b[A\n",
      " 93%|█████████▎| 9209/9944 [00:20<00:02, 337.93it/s]\u001b[A\n",
      " 93%|█████████▎| 9247/9944 [00:20<00:01, 348.82it/s]\u001b[A\n",
      " 93%|█████████▎| 9284/9944 [00:20<00:01, 354.39it/s]\u001b[A\n",
      " 94%|█████████▎| 9320/9944 [00:20<00:01, 355.97it/s]\u001b[A\n",
      " 94%|█████████▍| 9361/9944 [00:20<00:01, 369.25it/s]\u001b[A\n",
      " 95%|█████████▍| 9399/9944 [00:20<00:01, 365.76it/s]\u001b[A\n",
      " 95%|█████████▍| 9436/9944 [00:20<00:01, 354.33it/s]\u001b[A\n",
      " 95%|█████████▌| 9473/9944 [00:20<00:01, 358.55it/s]\u001b[A\n",
      " 96%|█████████▌| 9510/9944 [00:21<00:01, 348.04it/s]\u001b[A\n",
      " 96%|█████████▌| 9545/9944 [00:21<00:01, 331.16it/s]\u001b[A\n",
      " 96%|█████████▋| 9579/9944 [00:21<00:01, 327.45it/s]\u001b[A\n",
      " 97%|█████████▋| 9614/9944 [00:21<00:00, 331.92it/s]\u001b[A\n",
      " 97%|█████████▋| 9657/9944 [00:21<00:00, 354.96it/s]\u001b[A\n",
      " 98%|█████████▊| 9704/9944 [00:21<00:00, 381.83it/s]\u001b[A\n",
      " 98%|█████████▊| 9754/9944 [00:21<00:00, 410.56it/s]\u001b[A\n",
      " 99%|█████████▊| 9808/9944 [00:21<00:00, 442.04it/s]\u001b[A\n",
      " 99%|█████████▉| 9862/9944 [00:21<00:00, 466.34it/s]\u001b[A\n",
      "100%|█████████▉| 9917/9944 [00:21<00:00, 487.92it/s]\u001b[A\n",
      "100%|██████████| 9944/9944 [00:22<00:00, 451.25it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "VOTES = 16\n",
    "total = correct = 0\n",
    "\n",
    "with open('../input/test.json') as file, open('output.csv', 'w') as outputf:\n",
    "    for record in tqdm(json.load(file)):\n",
    "        ingredients_ids = []\n",
    "        for ingredient in record['ingredients']:\n",
    "            ingredient = normalize_name(ingredient)\n",
    "            if ingredient is None:\n",
    "                continue\n",
    "                \n",
    "            ingredient = ingredient.split(' ')\n",
    "            \n",
    "            ingredient = [WORDS[i] for i in ingredient if i in WORDS]\n",
    "            \n",
    "            if len(ingredient):\n",
    "                ingredients_ids.append(ingredient)\n",
    "                \n",
    "        qs = []\n",
    "        for i in range(VOTES):\n",
    "            igs = random.choices(ingredients_ids, k=MAX_INGREDIENT_COUNT)\n",
    "            igs = [random.choices(j, k=MAX_INGREDIENT_DIM) for j in igs]\n",
    "            qs.append(igs)\n",
    "#         print(qs)\n",
    "        y = model.predict(np.array(qs))\n",
    "#         print(y.shape)\n",
    "        y = np.sum(y, axis=0)\n",
    "#         print(y.shape)\n",
    "#         print(y)\n",
    "        cuisine = CUISINES[np.argmax(y)]\n",
    "#         if cuisine == record['cuisine']:\n",
    "#             correct += 1\n",
    "#         total += 1\n",
    "#         break\n",
    "        outputf.write(f\"{record['id']},{cuisine}\\n\")\n",
    "# print(100.0*correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
